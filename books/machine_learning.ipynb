{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 模型评估与选择\n",
    "---\n",
    "> 在进行模型训练时，首先要确定模型的**评估方法**，主要的任务即选择以某种方式对数据集划分为训练集和测试集，常用的划分方法有留出法、交叉验证法、自助法。然后就是开始训练得出模型结果，这个结果用**性能度量**来衡量这次训练的结果，常用的性能度量有错误率和精准率。\n",
    "模型需要**评估方法** 确定训练集和测试集，需要 **性能度量** 进行错误率的选择。**用某种实验评估方法测得学习器的某个性能度量结果** ，使用 **比较检验** 选择最优度量结果。 最后需要用**交叉检验**来比较算法性能。\n",
    "\n",
    "- error rate\n",
    "- accuracy\n",
    "- error\n",
    "    - training error(empirical error)\n",
    "    - generalization error\n",
    "- fitting\n",
    "    - overfitting\n",
    "    - underfitting\n",
    "\n",
    "## 2.2 模型的评估方法\n",
    "即确定train data, validation data, test data\n",
    "\n",
    "- 留出法(hold out)\n",
    "- 交叉验证法(k-fold cross validation)\n",
    "- 自助法:从样本池中随机选择一个，作为训练集。\n",
    "- 调参\n",
    "    - 算法参数(超参数)，参数数量不多\n",
    "    - 模型参数，参数数量超多\n",
    "\n",
    "## 2.3 performance measure\n",
    "- error rate and accuracy\n",
    "- 查准率和查全率与F1(以准确率为主还是以覆盖率为主，F1则依据参数结合了两个)\n",
    "- ROC and AUC \n",
    "- 代价敏感错误率与代价曲线:用于对错误率敏感的情形。\n",
    "\n",
    "## 2.4 比较检验\n",
    "- 假设检验：用测试错误率来衡量泛化错误率\n",
    "- 交叉验证t检验\n",
    "- McNemar检验：**交叉验证t检验和McNemar检验是比较一个数据集上的两个算法的性能。**\n",
    "- Friedman检验和Nemenyi后续检验：用于**一组数据集** 上的 **多个算法性能** 的比较。\n",
    "\n",
    "## 2.5 偏差与方差\n",
    "用于解释学习算法 **泛化性能** 的一种重要工具。\n",
    "\n",
    "\n",
    "<hr style=\"border:none;border-top:3px solid #5bc0de\"/>\n",
    "\n",
    "\n",
    "# 3 线性模型\n",
    "---\n",
    "> 线性模型可以处理线性问题，分类问题(二分类，多分类)。常用的线性问题用**线性回归**模型处理，线性模型的二分类模型有**逻辑回归模型**和**线性判别模型**。在处理多分类问题时，常用做法是把多分类分解成若干个二分类，再用二分类模型来处理。在进行分类问题时，通常会遇到的问题有**类别不平衡**，即训练数据正反例数量相差过大的问题，通常有三种解决方案。\n",
    "\n",
    "## 3.2 线性回归\n",
    "\n",
    "## 3.3 对数几率回归(逻辑回归) 二分类\n",
    "线性回归常用于线性预测，而如果想用线性模型处理**分类问题**，则需要采用对数几率回归logistic regression，**二分类**。\n",
    "\n",
    "## 3.4 线性判别分析 二分类\n",
    "Linear Discriminant Analysis(LDA):线性学习方法。将样本投影到一条直线上，同类的尽可能近，异类尽可能远, **二分类**。\n",
    "\n",
    "## 3.5 多分类\n",
    "- 多把分类拆分成多个二分类\n",
    "\n",
    "## 3.6 类别不平衡\n",
    "在处理分类问题时，常因训练集中的正反例类别不平衡，影响学习模型结果，常处理的方法有：\n",
    "- 对多的样本欠采样\n",
    "- 对少的样本过采样\n",
    "- 在预测时，添加阈值\n",
    "\n",
    "\n",
    "<hr style=\"border:none;border-top:3px solid #5bc0de\"/>\n",
    "\n",
    "\n",
    "# 4 决策树\n",
    "---\n",
    "> 决策树是常见的机器学习算法，依据不同的分支划分条件的不同，生成不同的决策树算法，目前常用的决策树算法有**ID3, C4.5, CART**,分别使用了**信息增益、增益率、基尼指数**作为划分选择。在进行决策树学习算法的训练中，为处理**过拟合**问题，采用了**剪枝处理**，包括预剪枝和后剪枝。如果样本数据是连续属性，需要先进行**离散化处理**，对于样本中的缺失值，进行**缺失值处理**。最后提到了多变量决策树。\n",
    "\n",
    "## 4.2 划分选择\n",
    "确定最优划分属性。在进行分支前，我们需要确定该以那种属性作为划分依据，依据不同的划分标准，衍生出不同的决策树算法。如采用信息增益的ID3决策树算法，使用增益率的C4.5, 使用基尼指数的CART。\n",
    "\n",
    "- 信息增益：ID3\n",
    "- 增益率：C4.5\n",
    "- 基尼指数：CART\n",
    "\n",
    "## 4.3 剪枝处理\n",
    "剪枝(pruning)主要处理“过拟合”，包括预剪枝和后剪枝。\n",
    "\n",
    "- 预剪枝\n",
    "- 后剪枝\n",
    "\n",
    "## 4.4 连续与缺失值\n",
    "\n",
    "- 连续值处理：连续属性生成决策树，需要先对连续属性离散化，采用二分法。\n",
    "- 缺失值处理：处理样本中的缺失值。\n",
    "\n",
    "## 4.5 多变量决策树\n",
    "如果样本含有多个属性，则需要考虑多变量决策树。\n",
    "\n",
    "<hr style=\"border:none;border-top:3px solid #5bc0de\"/>\n",
    "\n",
    "\n",
    "# 神经网络\n",
    "---\n",
    "\n",
    "<hr style=\"border:none;border-top:3px solid #5bc0de\"/>\n",
    "\n",
    "# 支持向量机\n",
    "---\n",
    "\n",
    "# 贝叶斯分类器\n",
    "---\n",
    "\n",
    "# 集成学习\n",
    "---\n",
    "\n",
    "# 聚类\n",
    "---\n",
    "\n",
    "# 降维与度量学习\n",
    "---\n",
    "\n",
    "# 特征选择与稀疏学习\n",
    "---\n",
    "\n",
    "# 计算学习理论\n",
    "---\n",
    "\n",
    "# 半监督学习\n",
    "---\n",
    "\n",
    "# 概率图模型\n",
    "---\n",
    "\n",
    "# 规则学习\n",
    "---\n",
    "\n",
    "# 强化学习\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
